"""
Script de verifica√ß√£o de GPU antes de executar o pipeline.
"""
import torch

print("="*70)
print("üîç VERIFICA√á√ÉO DE GPU")
print("="*70)

print(f"\nüì¶ PyTorch version: {torch.__version__}")
print(f"üñ•Ô∏è  CUDA dispon√≠vel: {'‚úÖ SIM' if torch.cuda.is_available() else '‚ùå N√ÉO'}")

if torch.cuda.is_available():
    print(f"üìä N√∫mero de GPUs: {torch.cuda.device_count()}")
    for i in range(torch.cuda.device_count()):
        print(f"\n   GPU {i}:")
        print(f"      Nome: {torch.cuda.get_device_name(i)}")
        props = torch.cuda.get_device_properties(i)
        print(f"      Mem√≥ria total: {props.total_memory / 1e9:.2f} GB")
        print(f"      Compute capability: {props.major}.{props.minor}")
        print(f"      Multi-processors: {props.multi_processor_count}")
    
    # Testar aloca√ß√£o
    print(f"\nüß™ Teste de aloca√ß√£o GPU...")
    try:
        x = torch.randn(1000, 1000).cuda()
        print(f"   ‚úÖ Tensor alocado na GPU com sucesso!")
        print(f"   Device: {x.device}")
        del x
        torch.cuda.empty_cache()
    except Exception as e:
        print(f"   ‚ùå Erro ao alocar: {e}")
else:
    print("\n‚ö†Ô∏è  GPU n√£o dispon√≠vel. Pipeline rodar√° em CPU (mais lento).")
    print("   Para habilitar GPU, verifique:")
    print("   1. Driver NVIDIA instalado")
    print("   2. CUDA Toolkit instalado")
    print("   3. PyTorch com suporte CUDA: pip install torch --index-url https://download.pytorch.org/whl/cu118")

print("\n" + "="*70)
