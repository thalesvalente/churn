"""
Pipeline Completo: Do dataset cru atÃ© os resultados finais.
Executa todas as etapas:
  00. PreparaÃ§Ã£o de dados (dataset.xlsx â†’ train/val/test splits)
  01. Clustering semÃ¢ntico
  02. Feature engineering  
  03. Treinamento de modelo

ExecuÃ§Ã£o:
    conda run -n ml python scripts/run_complete_pipeline.py
"""
import sys
from pathlib import Path
import time

# Adicionar src ao path
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.preprocessing.data_preparation import DataPreparation
from src.preprocessing.semantic_clustering import enrich_datasets
from src.preprocessing.feature_engineering import engineer_all_datasets
from src.training.train_gradient_boosting import GradientBoostingTrainer
from src.utils.logger import logger
from src.utils.report_generator import generate_technical_report
from src.config import config


def print_header():
    """Imprime cabeÃ§alho do pipeline."""
    logger.info("")
    logger.info("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    logger.info("â•‘                                                                                â•‘")
    logger.info("â•‘               ğŸš€ PIPELINE COMPLETO - DO ZERO AO RESULTADO ğŸš€                   â•‘")
    logger.info("â•‘                                                                                â•‘")
    logger.info("â•‘  Etapas:                                                                       â•‘")
    logger.info("â•‘    00. PreparaÃ§Ã£o de dados (dataset.xlsx â†’ splits)                            â•‘")
    logger.info("â•‘    01. Clustering semÃ¢ntico (Sentence Transformers + KMeans)                  â•‘")
    logger.info("â•‘    02. Feature engineering (37 features)                                      â•‘")
    logger.info("â•‘    03. Treinamento Gradient Boosting                                          â•‘")
    logger.info("â•‘                                                                                â•‘")
    logger.info("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    logger.info("")


def step_00_prepare_data() -> tuple:
    """
    ETAPA 00: PreparaÃ§Ã£o de dados crus.
    
    Returns:
        Tuple com caminhos (train_path, validation_path, test_path)
    """
    logger.info("=" * 80)
    logger.info("ğŸ“Š ETAPA 00/04: PREPARAÃ‡ÃƒO DE DADOS CRUS")
    logger.info("=" * 80)
    
    preparer = DataPreparation(
        raw_data_path='data/raw/dataset.xlsx',
        output_dir='data/raw',
        random_state=42
    )
    
    train_path, val_path, test_path = preparer.prepare()
    
    logger.success("âœ… ETAPA 00 CONCLUÃDA")
    logger.info("")
    
    return train_path, val_path, test_path


def step_01_semantic_clustering():
    """ETAPA 01: Clustering semÃ¢ntico."""
    logger.info("=" * 80)
    logger.info("ğŸ§  ETAPA 01/04: CLUSTERING SEMÃ‚NTICO")
    logger.info("=" * 80)
    
    enrich_datasets()
    
    logger.success("âœ… ETAPA 01 CONCLUÃDA")
    logger.info("")


def step_02_feature_engineering():
    """ETAPA 02: Feature engineering."""
    logger.info("=" * 80)
    logger.info("âš™ï¸  ETAPA 02/04: FEATURE ENGINEERING")
    logger.info("=" * 80)
    
    engineer_all_datasets()
    
    logger.success("âœ… ETAPA 02 CONCLUÃDA")
    logger.info("")


def step_03_train_model():
    """ETAPA 03: Treinamento do modelo."""
    logger.info("=" * 80)
    logger.info("ğŸ¤– ETAPA 03/04: TREINAMENTO GRADIENT BOOSTING")
    logger.info("=" * 80)
    
    trainer = GradientBoostingTrainer()
    trainer.train()
    
    logger.success("âœ… ETAPA 03 CONCLUÃDA")
    logger.info("")


def print_summary(elapsed_time: float):
    """Imprime sumÃ¡rio final."""
    logger.info("")
    logger.info("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    logger.info("â•‘                                                                                â•‘")
    logger.info("â•‘                     ğŸ‰ PIPELINE COMPLETO EXECUTADO! ğŸ‰                         â•‘")
    logger.info("â•‘                                                                                â•‘")
    logger.info(f"â•‘  â±ï¸  Tempo total: {elapsed_time:.1f} minutos                                         â•‘")
    logger.info("â•‘                                                                                â•‘")
    logger.info("â•‘  ğŸ“Š Artefatos gerados:                                                         â•‘")
    logger.info("â•‘     - data/raw/train.xlsx, validation.xlsx, test.xlsx                         â•‘")
    logger.info("â•‘     - data/processed/*_with_all_tabs_semantics.xlsx                           â•‘")
    logger.info("â•‘     - data/features/*_features_engineered.csv                                 â•‘")
    logger.info("â•‘     - models/experiments/gradient_boosting_churn.joblib                       â•‘")
    logger.info("â•‘     - outputs/metrics/gb_results.csv                                          â•‘")
    logger.info("â•‘     - outputs/metrics/gb_feature_importance.csv                               â•‘")
    logger.info("â•‘                                                                                â•‘")
    logger.info("â•‘  ğŸ” PrÃ³ximo passo:                                                             â•‘")
    logger.info("â•‘     conda run -n ml python compare_results.py                                 â•‘")
    logger.info("â•‘                                                                                â•‘")
    logger.info("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    logger.info("")


def main():
    """Executar pipeline completo."""
    start_time = time.time()
    
    # Configurar log em arquivo
    from pathlib import Path
    log_dir = Path('outputs/logs')
    log_dir.mkdir(parents=True, exist_ok=True)
    logger.add_file_handler(log_dir, prefix="complete_pipeline")
    
    print_header()
    
    try:
        # Etapa 00: PreparaÃ§Ã£o de dados
        step_00_prepare_data()
        
        # Etapa 01: Clustering semÃ¢ntico
        step_01_semantic_clustering()
        
        # Etapa 02: Feature engineering
        step_02_feature_engineering()
        
        # Etapa 03: Treinamento do modelo
        step_03_train_model()
        
        # SumÃ¡rio final
        elapsed_time = (time.time() - start_time) / 60
        print_summary(elapsed_time)
        
        # Gerar relatÃ³rio tÃ©cnico
        logger.info("")
        report_path = generate_technical_report(execution_time=elapsed_time)
        logger.info(f"ğŸ“„ RelatÃ³rio tÃ©cnico: {report_path}")
        logger.info("")
        
    except Exception as e:
        logger.error(f"âŒ ERRO no pipeline: {str(e)}")
        raise


if __name__ == '__main__':
    main()
