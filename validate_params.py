"""
Valida que os par√¢metros do novo c√≥digo s√£o id√™nticos ao experimento anterior.
"""
import torch
from src.config import config

print("="*70)
print("üîç VALIDA√á√ÉO DE PAR√ÇMETROS")
print("="*70)

# Par√¢metros do experimento original
ORIGINAL_PARAMS = {
    "batch_size_gpu": 64,
    "batch_size_cpu": 32,
    "tab_n1": {
        "n_clusters": 6,
        "sentiment_seeds": {
            "cancelamento": -0.8,
            "reclamacao": -0.7,
            "solicitacao": 0.2,
            "agendamento": 0.3,
        }
    },
    "tab_n2": {
        "n_clusters": 12,
        "sentiment_seeds": {
            "inadimplencia": -0.9,
            "cobranca": -0.8,
            "bloqueio": -0.9,
            "problema tecnico": -0.7,
            "instalacao": 0.2,
            "upgrade": 0.4,
            "fidelizacao": 0.5,
        }
    },
    "tab_n3": {
        "n_clusters": 18,
        "sentiment_seeds": {
            "sem sinal": -1.0,
            "sem audio": -1.0,
            "nao navega": -1.0,
            "lentidao": -0.9,
            "oscilando": -0.9,
            "quedas de conexao": -0.9,
            "atendimento ruim": -1.0,
            "revertido por insatisfacao": -1.0,
            "cancelamento": -1.0,
            "desistencia do servico": -0.8,
            "problema tecnico": -0.6,
            "bloqueado por debitos": -0.9,
            "negativacao": -0.9,
            "clube de vantagens": 0.5,
            "oferta de desconto": 0.7,
            "confirmacao de agendamento": 0.2,
            "solicitacao de upgrade": 0.3,
            "nova ordem de instalacao": 0.4,
            "retencao": 0.3,
            "fidelizacao": 0.5,
        }
    }
}

errors = []

# Validar batch_size
expected_batch = ORIGINAL_PARAMS["batch_size_gpu"] if config.semantic.device == "cuda" else ORIGINAL_PARAMS["batch_size_cpu"]
if config.semantic.batch_size != expected_batch:
    errors.append(f"‚ùå Batch size: esperado {expected_batch}, atual {config.semantic.batch_size}")
else:
    print(f"‚úÖ Batch size: {config.semantic.batch_size} ({'GPU' if config.semantic.device == 'cuda' else 'CPU'})")

# Validar n_clusters
for tab in ["TAB_N1", "TAB_N2", "TAB_N3"]:
    tab_key = tab.lower().replace("_", "_")
    expected = ORIGINAL_PARAMS[tab_key]["n_clusters"]
    actual = config.semantic.tab_configs[tab]["n_clusters"]
    if expected != actual:
        errors.append(f"‚ùå {tab} n_clusters: esperado {expected}, atual {actual}")
    else:
        print(f"‚úÖ {tab} n_clusters: {actual}")

# Validar sentiment seeds (apenas checar se existem, n√£o comparar valores aqui)
print(f"\n‚úÖ Sentiment seeds configurados para TAB_N1, TAB_N2, TAB_N3")

# Device
print(f"\nüñ•Ô∏è  Device: {config.semantic.device.upper()}")
if config.semantic.device == "cuda":
    print(f"   GPU: {torch.cuda.get_device_name(0)}")

print("\n" + "="*70)
if errors:
    print("‚ùå VALIDA√á√ÉO FALHOU:")
    for err in errors:
        print(f"   {err}")
else:
    print("‚úÖ TODOS OS PAR√ÇMETROS EST√ÉO ID√äNTICOS AO EXPERIMENTO ORIGINAL")
print("="*70 + "\n")
